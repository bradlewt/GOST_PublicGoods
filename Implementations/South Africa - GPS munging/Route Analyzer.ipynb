{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "from shapely.ops import unary_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Raw File Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = r'C:\\Users\\charl\\Documents\\GOST\\South Africa\\Connectivity\\Submission_15_12_2018'\n",
    "q = r'Recon_December.xlsx'\n",
    "\n",
    "Trips = pd.read_excel(os.path.join(p,q), sheet_name = 'Trips')\n",
    "Passengers = pd.read_excel(os.path.join(p,q), sheet_name = 'Passengers')\n",
    "\n",
    "RouteMaster = pd.read_excel(os.path.join(p,r'Route O-D_Master_21December2018.xlsx'))\n",
    "RouteMaster = RouteMaster[[\"UNIQUE ROUTE ID's\",'ORIGIN','DESTINATION']].set_index(\"UNIQUE ROUTE ID's\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match on useful fields from Trips frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(x):\n",
    "    try:\n",
    "        return (x.minute + x.hour * 60 + x.second / 60)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "Passengers['TT_minutes'] = Passengers['Travel Time'].apply(lambda x: convert(x))\n",
    "\n",
    "Trips = Trips.set_index('Trip ID')\n",
    "Passengers = Passengers.set_index('Trip ID')\n",
    "for i in ['Route Description','Start Coordinate', 'End Coordinate', 'Revenue', 'Start Time', 'Total Passengers', 'Distance']:\n",
    "          Passengers['Trip %s' % i] = Trips[i]\n",
    "Passengers = Passengers.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match on useful fields from RouteMaster frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Passengers = Passengers.set_index('Trip Route Description')\n",
    "Passengers['Trip Origin'] = RouteMaster['ORIGIN']\n",
    "Passengers['Trip Destination'] = RouteMaster['DESTINATION']\n",
    "Passengers = Passengers.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Handling: Remove Passengers where travel time, fare or trip distance values are erroneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Passengers = Passengers.loc[(Passengers['TT_minutes'] < 1000) & (Passengers['TT_minutes'] > 0)]\n",
    "Passengers = Passengers.loc[(Passengers['Fare'] < 1000) & (Passengers['Fare'] > 0)]\n",
    "Passengers = Passengers.loc[(Passengers['Trip Distance'] < 1000) & (Passengers['Trip Distance'] > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add fare per minute / unit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Passengers['Fare_per_minute'] = Passengers['Fare'] / Passengers['TT_minutes']\n",
    "Passengers['Fare_per_mile'] = Passengers['Fare'] / Passengers['Trip Distance']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passengers: Add on ward details for boarding / alightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Local\\Continuum\\anaconda3\\envs\\Cfox_2\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\charl\\AppData\\Local\\Continuum\\anaconda3\\envs\\Cfox_2\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "shp_pth = r'C:\\Users\\charl\\Documents\\GOST\\South Africa\\Connectivity\\Fwd__SAL\\1_Residential_SAL'\n",
    "ward_shp = gpd.read_file(os.path.join(shp_pth, 'wards_4326.shp'))\n",
    "ward_shp = ward_shp[['SL_WARD_KE','SL_SUB_CNC','geometry']]\n",
    "\n",
    "Passengers['P_ID'] = Passengers.index\n",
    "Bind_P = Passengers[['P_ID','Boarding Location','Alighting Location']]\n",
    "def convert_to_point(x):\n",
    "    l = x.split(', ')\n",
    "    return Point(float(l[0]), float(l[1]))\n",
    "    \n",
    "Bind_P['Boarding Point'] = Bind_P['Boarding Location'].apply(lambda x: convert_to_point(x))\n",
    "Bind_P['Alighting Point'] = Bind_P['Alighting Location'].apply(lambda x: convert_to_point(x))\n",
    "\n",
    "Q = gpd.GeoDataFrame(Bind_P, crs = ward_shp.crs, geometry = 'Boarding Point')\n",
    "boarding_join = gpd.sjoin(Q, ward_shp, how = 'left')\n",
    "boarding_join = boarding_join[['P_ID','SL_WARD_KE','SL_SUB_CNC']]\n",
    "boarding_join.columns = ['P_ID','Board_WARD_KE','Board_SUB_CNC']\n",
    "boarding_join = boarding_join.set_index('P_ID')\n",
    "\n",
    "Q2 = gpd.GeoDataFrame(Bind_P, crs = ward_shp.crs, geometry = 'Alighting Point')\n",
    "alighting_join = gpd.sjoin(Q2, ward_shp, how = 'left')\n",
    "alighting_join = alighting_join[['P_ID','SL_WARD_KE','SL_SUB_CNC']]\n",
    "alighting_join.columns = ['P_ID','Alight_WARD_KE','Alight_SUB_CNC']\n",
    "alighting_join = alighting_join.set_index('P_ID')\n",
    "\n",
    "Passengers = Passengers.set_index('P_ID')\n",
    "Passengers['Alight_WARD_KE'] = alighting_join['Alight_WARD_KE']\n",
    "Passengers['Alight_SUB_CNC'] = alighting_join['Alight_SUB_CNC']\n",
    "Passengers['Board_WARD_KE'] = boarding_join['Board_WARD_KE']\n",
    "Passengers['Board_SUB_CNC'] = boarding_join['Board_SUB_CNC']\n",
    "Passengers = Passengers.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passengers: Fare Summary Output Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_table = Passengers[['Ethnicity', 'Age Group', 'Gender', 'Fare', 'Fare_per_minute', 'Fare_per_mile', 'TT_minutes']].groupby(['Ethnicity']).median()\n",
    "age_table = Passengers[['Ethnicity', 'Age Group', 'Gender', 'Fare', 'Fare_per_minute', 'Fare_per_mile', 'TT_minutes']].groupby(['Age Group']).median()\n",
    "gender_table = Passengers[['Ethnicity', 'Age Group', 'Gender', 'Fare', 'Fare_per_minute', 'Fare_per_mile', 'TT_minutes']].groupby(['Gender']).median()\n",
    "gender_ethnicity_table = Passengers[['Ethnicity', 'Age Group', 'Gender', 'Fare', 'Fare_per_minute', 'Fare_per_mile', 'TT_minutes']].groupby(['Gender','Ethnicity']).median()\n",
    "age_ethnicity_table = Passengers[['Ethnicity', 'Age Group', 'Gender', 'Fare', 'Fare_per_minute', 'Fare_per_mile', 'TT_minutes']].groupby(['Age Group','Ethnicity']).median()\n",
    "full_table = Passengers[['Ethnicity', 'Age Group', 'Gender', 'Fare', 'Fare_per_minute', 'Fare_per_mile', 'TT_minutes']].groupby(['Gender','Age Group','Ethnicity']).median()\n",
    "tables = [ethnicity_table, age_table, gender_table, gender_ethnicity_table, age_ethnicity_table, full_table]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trip level analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Local\\Continuum\\anaconda3\\envs\\Cfox_2\\lib\\site-packages\\pandas\\core\\indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "unique_trips = list(set(Passengers['Trip Route Description']))\n",
    "Selected_trips = unique_trips[:10]\n",
    "trip_tables = []\n",
    "for t in Selected_trips:\n",
    "    Q = Passengers.loc[Passengers['Trip Route Description'].isin([t])]\n",
    "    ethnicities = ['BLACK','INDIAN','OTHER','WHITE','COLOURED']\n",
    "    genders = ['M','F']\n",
    "    ages = ['YOUNG','MIDDLE','OLD']\n",
    "    s = Q.copy()\n",
    "    \n",
    "    for gend in genders:\n",
    "        s[gend] = 0\n",
    "        s[gend].loc[s['Gender'] == gend] = 1\n",
    "    for ethn in ethnicities:\n",
    "        s[ethn] = 0\n",
    "        s[ethn].loc[s['Ethnicity'] == ethn] = 1\n",
    "    for age in ages:\n",
    "        s[age] = 0\n",
    "        s[age].loc[s['Age Group'] == age] = 1\n",
    "    s['Total'] = s['M'] + s['F']\n",
    "    col_keep = []\n",
    "    s['Trip_st_hour'] = s['Trip Start Time'].apply(lambda x: x.hour)\n",
    "    s = s.groupby('Trip_st_hour').sum()\n",
    "    s = s.sort_values(by = 'Trip_st_hour', ascending = True)\n",
    "    for ethn in ethnicities:\n",
    "        s['% {}'.format(ethn)] = s[ethn] / (s['Total'])\n",
    "        col_keep.append('% {}'.format(ethn))\n",
    "    for gend in genders:\n",
    "        s['% {}'.format(gend)] = s[gend] / (s['Total'])\n",
    "        col_keep.append('% {}'.format(gend))\n",
    "    for age in ages:\n",
    "        s['% {}'.format(age)] = s[age] / (s['Total'])\n",
    "        col_keep.append('% {}'.format(age)) \n",
    "    s = s[['M','F',*col_keep,]]\n",
    "    trip_tables.append(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route Summary: Initial Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "route_summary = Passengers[['Trip Route Description', 'Fare', 'Fare_per_minute', 'Fare_per_mile', 'TT_minutes']].groupby('Trip Route Description').median().sort_values(by = 'Fare_per_minute', ascending = False)\n",
    "route_summary['Origin'] = RouteMaster['ORIGIN']\n",
    "route_summary['Destination'] = RouteMaster['DESTINATION']\n",
    "\n",
    "s = Passengers[['Trip Route Description', 'Gender','Ethnicity','Age Group']]\n",
    "ethnicities = ['BLACK','INDIAN','OTHER','WHITE','COLOURED']\n",
    "genders = ['M','F']\n",
    "ages = ['YOUNG','MIDDLE','OLD']\n",
    "for gend in genders:\n",
    "    s[gend] = 0\n",
    "    s[gend].loc[s['Gender'] == gend] = 1\n",
    "for ethn in ethnicities:\n",
    "    s[ethn] = 0\n",
    "    s[ethn].loc[s['Ethnicity'] == ethn] = 1\n",
    "for age in ages:\n",
    "    s[age] = 0\n",
    "    s[age].loc[s['Age Group'] == age] = 1\n",
    "s = s.groupby('Trip Route Description').sum()\n",
    "s['Total'] = s['M'] + s['F']\n",
    "col_keep = []\n",
    "for ethn in ethnicities:\n",
    "    s['% {}'.format(ethn)] = s[ethn] / (s['Total'])\n",
    "    col_keep.append('% {}'.format(ethn))\n",
    "for gend in genders:\n",
    "    s['% {}'.format(gend)] = s[gend] / (s['Total'])\n",
    "    col_keep.append('% {}'.format(gend))\n",
    "for age in ages:\n",
    "    s['% {}'.format(age)] = s[age] / (s['Total'])\n",
    "    col_keep.append('% {}'.format(age))\n",
    "s = s[col_keep]\n",
    "for i in col_keep:\n",
    "    route_summary[i] = s[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route Summary: Match on Route WKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import fiona\n",
    "fiona.drvsupport.supported_drivers['kml'] = 'rw' # enable KML support which is disabled by default\n",
    "fiona.drvsupport.supported_drivers['KML'] = 'rw' # enable KML support which is disabled by default\n",
    "\n",
    "route_summary = route_summary.reset_index()\n",
    "set_of_routes = list(set(route_summary['Trip Route Description']))\n",
    "\n",
    "for root, folder, files in os.walk(r'C:\\Users\\charl\\Documents\\GOST\\South Africa\\Connectivity\\Submission_15_12_2018\\COCT_Dec'):\n",
    "    pass\n",
    "\n",
    "gathered = []\n",
    "geom_dict = {}\n",
    "for f in files:\n",
    "    route = f.split('_')[0]\n",
    "    if route in set_of_routes and route not in gathered:\n",
    "        if f.split('_')[2] == 'trip.kml':\n",
    "            f = gpd.read_file(os.path.join(root, f))\n",
    "            geom_dict[route] = f.geometry.iloc[0]\n",
    "            gathered.append(route)\n",
    "            \n",
    "geom_df = pd.DataFrame({'geometry':list(geom_dict.values())}, index = geom_dict.keys())\n",
    "route_summary = route_summary.set_index('Trip Route Description')\n",
    "route_summary['WKT'] = geom_df['geometry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route Summary: Match on Start / End Ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_summary = route_summary.reset_index()\n",
    "route_summary = route_summary.loc[route_summary.WKT.apply(type) != float]\n",
    "route_summary['Origin_Point'] = route_summary.WKT.apply(lambda x: Point((x.coords[0])))\n",
    "route_summary['Destination_Point'] = route_summary.WKT.apply(lambda x: Point((x.coords[-1])))\n",
    "\n",
    "trip_origin_df = route_summary[['Trip Route Description','Origin_Point']]\n",
    "trip_origin_df = gpd.GeoDataFrame(trip_origin_df, geometry = 'Origin_Point', crs = ward_shp.crs)\n",
    "trip_origin_join = gpd.sjoin(trip_origin_df, ward_shp, how = 'left')\n",
    "trip_origin_join = trip_origin_join.set_index('Trip Route Description')\n",
    "\n",
    "trip_dest_df = route_summary[['Trip Route Description','Destination_Point']]\n",
    "trip_dest_df = gpd.GeoDataFrame(trip_dest_df, geometry = 'Destination_Point', crs = ward_shp.crs)\n",
    "trip_dest_join = gpd.sjoin(trip_dest_df, ward_shp, how = 'left')\n",
    "trip_dest_join = trip_dest_join.set_index('Trip Route Description')\n",
    "\n",
    "route_summary = route_summary.set_index('Trip Route Description')\n",
    "route_summary['dest_ward_KE'] = trip_dest_join['SL_WARD_KE']\n",
    "route_summary['dest_SUB_CNC'] = trip_dest_join['SL_SUB_CNC']\n",
    "route_summary['origin_ward_KE'] = trip_origin_join['SL_WARD_KE']\n",
    "route_summary['origin_SUB_CNC'] = trip_origin_join['SL_SUB_CNC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time of Day: Generate Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Passengers.copy()\n",
    "s['Boarding Hour'] = s['Boarding Time'].apply(lambda x: x.hour)\n",
    "col_keep = []\n",
    "for gend in genders:\n",
    "    s[gend] = 0\n",
    "    s[gend].loc[s['Gender'] == gend] = 1\n",
    "    col_keep.append(gend)\n",
    "for ethn in ethnicities:\n",
    "    s[ethn] = 0\n",
    "    s[ethn].loc[s['Ethnicity'] == ethn] = 1\n",
    "    col_keep.append(ethn)\n",
    "for age in ages:\n",
    "    s[age] = 0\n",
    "    s[age].loc[s['Age Group'] == age] = 1\n",
    "    col_keep.append(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_averageing = s[['Boarding Hour','Fare','Fare_per_mile','Fare_per_minute','TT_minutes']]\n",
    "data_counting = s[['Boarding Hour',*col_keep]]\n",
    "data_averageing = data_averageing.groupby('Boarding Hour').median()\n",
    "data_counting = data_counting.groupby('Boarding Hour').sum()\n",
    "data = data_averageing.join(data_counting)\n",
    "data.columns = ['Median Fare','Median Fare per Mile', 'Median Fare per Minute', 'Median Trip Time (minutes)', *col_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = data.copy()\n",
    "s['Total'] = s['M'] + s['F']\n",
    "for ethn in ethnicities:\n",
    "    s['% {}'.format(ethn)] = s[ethn] / (s['Total'])\n",
    "for gend in genders:\n",
    "    s['% {}'.format(gend)] = s[gend] / (s['Total'])\n",
    "for age in ages:\n",
    "    s['% {}'.format(age)] = s[age] / (s['Total'])\n",
    "time_of_day = s.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(os.path.join(p, 'summary.xlsx')) as writer:\n",
    "    route_summary.to_excel(writer, sheet_name = 'RouteSummary')\n",
    "    time_of_day.to_excel(writer, sheet_name = 'HourlyAnalysis')\n",
    "    counter = 1\n",
    "    for table in tables:\n",
    "        table.to_excel(writer, sheet_name = 'table_%s' % counter)\n",
    "        counter +=1\n",
    "    counter = 1\n",
    "    for table in trip_tables:\n",
    "        table.to_excel(writer, sheet_name = '%s' % Selected_trips[counter - 1])\n",
    "        counter +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyis of Khayelitsha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_s = r'C:\\Users\\charl\\Documents\\GOST\\South Africa\\Connectivity\\Fwd__SAL'\n",
    "khay = gpd.read_file(os.path.join(p_s, 'Khayelitsha.shp'))\n",
    "\n",
    "khay_shp = unary_union(khay.geometry)\n",
    "khay_shp_gdf = gpd.GeoDataFrame({'geometry':khay_shp}, crs = {'init':'epsg:4326'}, index = [1], geometry = 'geometry')\n",
    "khay_shp_gdf.to_file(os.path.join(p_s, 'Khayelitsha_area.shp'), driver = 'ESRI Shapefile')\n",
    "khay_shp_gdf = khay_shp_gdf.to_crs({'init':'epsg:22234'})\n",
    "khay_shp_gdf.to_file(os.path.join(p_s, 'Khayelitsha_area_222234.shp'), driver = 'ESRI Shapefile')\n",
    "\n",
    "shp_pth = r'C:\\Users\\charl\\Documents\\GOST\\South Africa\\Connectivity\\Fwd__SAL\\1_Residential_SAL'\n",
    "ward_shp = gpd.read_file(os.path.join(shp_pth, 'wards_4326.shp'))\n",
    "ward_shp = ward_shp.to_crs({'init':'epsg:22234'})\n",
    "ward_shp.to_file(os.path.join(p_s, 'wards_222234.shp'), driver = 'ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "Passengers['Boarding Point'] = Passengers['Boarding Location'].apply(lambda x: convert_to_point(x))\n",
    "Passengers['Alighting Point'] = Passengers['Alighting Location'].apply(lambda x: convert_to_point(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "khay_p_boarding = gpd.GeoDataFrame(Passengers, crs = khay.crs, geometry = 'Boarding Point')\n",
    "khay_p_boarding['Boarding Time hour'] = khay_p_boarding['Boarding Time'].apply(lambda x: x.hour)\n",
    "khay_p_boarding = khay_p_boarding.loc[khay_p_boarding.intersects(khay_shp) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "khay_p_boarding = khay_p_boarding.to_crs({'init':'epsg:22234'})\n",
    "khay_p_boarding.to_csv(os.path.join(p, 'khay.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "khay_p_boarding_men = khay_p_boarding.loc[khay_p_boarding['Gender'] == 'M']\n",
    "khay_p_boarding_men.to_csv(os.path.join(p, 'khay_boarding_men.csv'))\n",
    "khay_p_boarding_women = khay_p_boarding.loc[khay_p_boarding['Gender'] == 'F']\n",
    "khay_p_boarding_women.to_csv(os.path.join(p, 'khay_boarding_women.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "khay_p_alighting = gpd.GeoDataFrame(Passengers, crs = khay.crs, geometry = 'Alighting Point')\n",
    "khay_p_alighting['Alighting Time hour'] = khay_p_alighting['Alighting Time'].apply(lambda x: x.hour)\n",
    "khay_p_alighting = khay_p_alighting.loc[khay_p_alighting.intersects(khay_shp) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "khay_p_alighting = khay_p_alighting.to_crs({'init':'epsg:22234'})\n",
    "khay_p_alighting_men = khay_p_alighting.loc[khay_p_alighting['Gender'] == 'M']\n",
    "khay_p_alighting_men.to_csv(os.path.join(p, 'khay_alighting_men.csv'))\n",
    "khay_p_alighting_women = khay_p_alighting.loc[khay_p_alighting['Gender'] == 'F']\n",
    "khay_p_alighting_women.to_csv(os.path.join(p, 'khay_alighting_women.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_pth = r'C:\\Users\\charl\\Documents\\GOST\\South Africa\\Connectivity\\Fwd__SAL\\1_Residential_SAL'\n",
    "ward_shp = gpd.read_file(os.path.join(shp_pth, 'wards_4326.shp'))\n",
    "ward_shp['centroid'] = ward_shp.geometry.centroid\n",
    "match_ward = ward_shp[['SL_WARD_KE','centroid']].set_index('SL_WARD_KE')\n",
    "match_ward['centroid'].loc[5177473] = Point(18.3918, -33.9201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "khayelitsha_wards = [5177561,5177559, 5177557, 5177555, 5177553, 5177551, 5177549, 5177547, 5177545, 5177543]\n",
    "times = {'morning':[7,8,9],'midday':[11,12,13],'evening':[16,17,8,19]}\n",
    "outs = []\n",
    "for t in times:\n",
    "    HRS = times[t]\n",
    "    binz = []\n",
    "    for ward in khayelitsha_wards:\n",
    "        Q = khay_p_boarding.copy()\n",
    "        Q = Q.loc[Q['Boarding Time hour'].isin(HRS)]\n",
    "        q = Q.loc[Q.Board_WARD_KE == ward]\n",
    "        dest = q.Alight_WARD_KE.value_counts().to_frame()\n",
    "        dest = dest.reset_index()\n",
    "        dest.columns = ['D_ID','count']\n",
    "        dest['O_ID'] = ward\n",
    "        binz.append(dest)\n",
    "    df2 = pd.concat(binz)\n",
    "    df2['time'] = str(t)\n",
    "    outs.append(df2)\n",
    "\n",
    "ins = []\n",
    "for t in times:\n",
    "    HRS = times[t]\n",
    "    binz = []\n",
    "    for ward in khayelitsha_wards:\n",
    "        Q = khay_p_alighting.copy()\n",
    "        Q = Q.loc[Q['Alighting Time hour'].isin(HRS)]\n",
    "        q = Q.loc[Q.Alight_WARD_KE == ward]\n",
    "        orig = q.Board_WARD_KE.value_counts().to_frame()\n",
    "        orig = orig.reset_index()\n",
    "        orig.columns = ['O_ID','count']\n",
    "        orig['D_ID'] = ward\n",
    "        binz.append(orig)\n",
    "    df2 = pd.concat(binz)\n",
    "    df2['time'] = str(t)\n",
    "    ins.append(df2)\n",
    "\n",
    "nets = []\n",
    "for i in range(0, len(ins)):\n",
    "    A = ins[i]\n",
    "    A['combo'] = A['O_ID'].astype(str) + ' | ' + A['D_ID'].astype(str)\n",
    "    A = A.rename({'count':'inflow'}, axis = 1)\n",
    "    A = A[['inflow','combo']].set_index('combo')\n",
    "    B = outs[i]\n",
    "    B['combo'] = B['D_ID'].astype(str) + ' | ' + B['O_ID'].astype(str)\n",
    "    B = B.rename({'count':'outflow'}, axis = 1)\n",
    "    B = B[['outflow','combo']].set_index('combo')\n",
    "    C = A.join(B, how = 'outer')\n",
    "    C['inflow'] = C['inflow'].fillna(0)\n",
    "    C['outflow'] = C['outflow'].fillna(0)\n",
    "    C['net'] = C['inflow'] - C['outflow']\n",
    "    C = C.sort_values(by = 'net', ascending = False)\n",
    "    C['time'] = list(times.keys())[i]\n",
    "    C = C.reset_index()\n",
    "    C['O_ID'] = C['combo'].apply(lambda x: x.split(' | ')[0]).astype(float)\n",
    "    C['D_ID'] = C['combo'].apply(lambda x: x.split(' | ')[1]).astype(float)\n",
    "    nets.append(C)\n",
    "\n",
    "for X in ['combined','disagg']:\n",
    "    if X == 'disagg':\n",
    "        for i in range(0, len(nets)):\n",
    "            df2 = nets[i]\n",
    "            time_of_day = list(times.keys())[i]\n",
    "            df = df2.copy()\n",
    "            df = df.set_index('D_ID')\n",
    "            df['D_Point'] = match_ward['centroid']\n",
    "            df = df.reset_index().set_index('O_ID')\n",
    "            df['O_Point'] = match_ward['centroid']\n",
    "            df = df.reset_index()\n",
    "            df['journey'] = df['O_ID'].astype(str) + ' to ' + df['D_ID'].astype(str)\n",
    "            df['WKT'] = df.apply(lambda x: LineString([x.O_Point,x.D_Point]), axis = 1)\n",
    "            df.to_csv(os.path.join(p, 'Khayelitsha', '{}_{}.csv'.format(time_of_day, X)))\n",
    "    elif X == 'combined':\n",
    "        for i in range(0, len(nets)):\n",
    "            time_of_day = list(times.keys())[i]\n",
    "            df2 = nets[i]\n",
    "            df2 = df2[['net','time','D_ID','O_ID']]\n",
    "            df2 = df2.groupby('O_ID').sum().reset_index()\n",
    "            df = df2.copy()\n",
    "            df = df.set_index('D_ID')\n",
    "            df['D_Point'] = khay_shp.centroid\n",
    "            df = df.reset_index().set_index('O_ID')\n",
    "            df['O_Point'] = match_ward['centroid']\n",
    "            df = df.reset_index()\n",
    "            df['journey'] = df['O_ID'].astype(str) + ' to ' + df['D_ID'].astype(str)\n",
    "            df['WKT'] = df.apply(lambda x: LineString([x.O_Point,x.D_Point]), axis = 1)\n",
    "            df.to_csv(os.path.join(p, 'Khayelitsha', '{}_{}.csv'.format(time_of_day, X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Cfox2)",
   "language": "python",
   "name": "cfox2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
