{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
   ],
   "source": [
    "import solaris as sol\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import skimage\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import torch\n",
    "import scipy\n",
    "from shapely.ops import cascaded_union  # just for visualization purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the model\n",
    "\n",
    "### Creating training masks\n",
    "Before we can continue training a model, we need target masks: images that the model will learn to create during training. We'll follow [this tutorial](https://solaris.readthedocs.io/en/latest/tutorials/notebooks/api_masks_tutorial.html) to create masks. __Note for workshop participants:__ this cell won't work because the `/data` directory is read-only; we've made the training masks for you, but this cell shows how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wb447340/Notebooks/Imagery/solaris\n",
      "/home/wb447340/Notebooks/Imagery/Feature_Extraction\n",
      "/home/public/Data/COUNTRY/GHA/chippedbasemap_512\n",
      "/home/public/Data/COUNTRY/GHA/chippedbasemap_512/images\n",
      "/home/public/Data/COUNTRY/GHA/chippedbasemap_512/labels\n"
     ]
    }
   ],
   "source": [
    "sol_path = '/home/wb447340/Notebooks/Imagery/solaris'\n",
    "data_path_p = '/home/wb447340/Notebooks/Imagery/Feature_Extraction'\n",
    "data_path_j = '/home/public/Data/COUNTRY/GHA/chippedbasemap_512'\n",
    "data_path_train = '/home/public/Data/COUNTRY/GHA/TRAINING_DATA/RGB'\n",
    "images = data_path_j + '/images'\n",
    "masks = data_path_j + '/labels'\n",
    "print(sol_path)\n",
    "print(data_path_p)\n",
    "print(data_path_j)\n",
    "print(images)\n",
    "print(masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if you can see your image chips, assemble the input list of chips as a CSV, and make sure they will be read in as a tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you see the public drive with the data?\n",
    "os.path.exists(data_path_j)\n",
    "print(os.listdir(data_path_j))\n",
    "os.path.exists(data_path_p)\n",
    "print(os.listdir(data_path_p))\n",
    "os.path.exists(data_path_train)\n",
    "print(os.listdir(data_path_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create chips of imagery from COG tiles, then assemble a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputTileFolder = \"/home/public/Data/COUNTRY/GHA/basemap/raster_tiles/\"\n",
    "allImagetiles = []\n",
    "for root, dirs, files in os.walk(inputTileFolder):\n",
    "    for f in files:\n",
    "        allImagetiles.append(os.path.join(root, f))\n",
    "​\n",
    "imgCnt = 0\n",
    "​\n",
    "for cImg in allImagetiles[:100]:\n",
    "    imgCnt = imgCnt + 1\n",
    "    if imgCnt > 100:\n",
    "        break\n",
    "    curR = rasterio.open(cImg)\n",
    "    chipSize = 512\n",
    "    tileName = os.path.basename(cImg).replace(\".tif\", \"\")\n",
    "    print(\"Processing %s of 100: %s\" % (imgCnt, tileName))\n",
    "    \n",
    "    \n",
    "    baseOutFolder = \"/home/public/Data/COUNTRY/GHA/chippedbasemap_%s\" % chipSize\n",
    "    outFolder = os.path.join(baseOutFolder, tileName)\n",
    "    misOut = \"%s_misshapen\" % outFolder\n",
    "    if not os.path.exists(outFolder):\n",
    "        os.makedirs(outFolder)\n",
    "    if not os.path.exists(misOut):\n",
    "        os.makedirs(misOut)\n",
    "​\n",
    "    prof = {'driver': 'GTiff', \n",
    "            'dtype': 'uint8', \n",
    "            'nodata': None, \n",
    "            'count': 3,\n",
    "            'StripOffsets': 1\n",
    "    }\n",
    "​\n",
    "    xRange = list(range(0, curR.shape[0], chipSize)) + [curR.shape[0]]\n",
    "    yRange = list(range(0, curR.shape[1], chipSize)) + [curR.shape[1]]\n",
    "​\n",
    "    allImages = []\n",
    "    with rasterio.open(cImg) as src:\n",
    "        prof.update(crs=src.crs)\n",
    "        for xIdx in range(1, len(xRange)):\n",
    "            for yIdx in range(1, len(yRange)):\n",
    "                outFile = os.path.join(outFolder, \"chip_%s_%s_%s.tif\" % (tileName, xIdx, yIdx))            \n",
    "                if not os.path.exists(outFile):\n",
    "                    curWindow = Window.from_slices((xRange[xIdx - 1], xRange[xIdx]),\n",
    "                                               (yRange[yIdx - 1], yRange[yIdx]))\n",
    "                    temp = src.read([1,2,3], window=curWindow)\n",
    "                    if temp.shape[1] != chipSize or temp.shape[2] != chipSize:\n",
    "                        outFile = os.path.join(misOut, \"chip_%s_%s.tif\" % (xIdx, yIdx))\n",
    "                    else:\n",
    "                        allImages.append(outFile)\n",
    "                        \n",
    "                    prof.update(transform=transform(curWindow, transform=src.transform),\n",
    "                            width=temp.shape[2], height=temp.shape[1])            \n",
    "                    with rasterio.open(outFile, 'w', **prof) as dst:\n",
    "                        dst.write(temp)\n",
    "​\n",
    "    with open(\"%s.csv\" % outFolder, 'w') as fileList:\n",
    "        cnt=0\n",
    "        fileList.write(\",image\\n\")\n",
    "        for line in allImages:\n",
    "            fileList.write(\"%s,%s\\n\" % (cnt, line.replace(\"/home/wb411133/data/Country\",\"/home/public/Data/COUNTRY\")))\n",
    "            cnt += 1\n",
    "​\n",
    "# Combine csv files into one file\n",
    "baseOutFolder =\"/home/public/Data/COUNTRY/GHA/chippedbasemap_512\"\n",
    "allCsv = []\n",
    "allTif = []\n",
    "rgbImages = []\n",
    "grayImages = []\n",
    "mixedImages = []\n",
    "for root, dirs, files in os.walk(baseOutFolder):\n",
    "    for f in files:\n",
    "        if f[-4:] == \".csv\":\n",
    "            allCsv.append(os.path.join(root, f))\n",
    "        if f[-4:] == \".tif\" and root[-6:] != \"shapen\" and root[-3:] != \"nt8\":\n",
    "            fileName = os.path.join(root, f)\n",
    "            allTif.append(fileName)\n",
    "            #Calculate grayness of the image\n",
    "            temp = rasterio.open(fileName).read()            \n",
    "            sampleX = random.sample(range(0, temp.shape[1]), 10)\n",
    "            sampleY = random.sample(range(0, temp.shape[2]), 10)\n",
    "            pGray = 0\n",
    "            for x in range(0,10):\n",
    "                cTemp = temp[:,sampleX[x],sampleY[x]]\n",
    "                if (cTemp[0] == cTemp[1] == cTemp[2]):\n",
    "                    pGray += 1\n",
    "            if pGray == 10:\n",
    "                grayImages.append(fileName)\n",
    "            elif pGray == 0:\n",
    "                rgbImages.append(fileName)\n",
    "            else:\n",
    "                mixedImages.append(fileName)\n",
    "                \n",
    "cnt = 0\n",
    "with open(os.path.join(baseOutFolder, \"all_images_INF_GREY.csv\"), 'w') as out:\n",
    "    out.write(\",image\\n\")\n",
    "    for f in grayImages:\n",
    "        out.write(\"%s,%s\\n\" % (cnt, f))\n",
    "        cnt = cnt + 1\n",
    "​\n",
    "cnt = 0\n",
    "with open(os.path.join(baseOutFolder, \"all_images_INF_RGB.csv\"), 'w') as out:\n",
    "    out.write(\",image\\n\")\n",
    "    for f in rgbImages:\n",
    "        out.write(\"%s,%s\\n\" % (cnt, f))\n",
    "        cnt = cnt + 1\n",
    "​\n",
    "cnt = 0\n",
    "with open(os.path.join(baseOutFolder, \"all_images_INF_MIXED.csv\"), 'w') as out:\n",
    "    out.write(\",image\\n\")\n",
    "    for f in mixedImages:\n",
    "        out.write(\"%s,%s\\n\" % (cnt, f))\n",
    "        cnt = cnt + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the shape of in the input tensors that pytorch will read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inCSV = os.path.join(data_path_train,'GHA_train_lnx.csv')\n",
    "print(inCSV)\n",
    "inD = pd.read_csv(inCSV)\n",
    "for idx, row in inD.iterrows():\n",
    "    try:\n",
    "        cImg = skimage.io.imread(row['image'][1])\n",
    "        print(cImg.shape)\n",
    "    except:\n",
    "        print(row['image'])\n",
    "print(inD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can you import your Multispectral input chips?\n",
    "snapshot_RGB = skimage.io.imread('//home/public/Data/COUNTRY/GHA/TRAINING_DATA/RGB/images/000000000.tif')\n",
    "snapshot_PAN = skimage.io.imread('//home/public/Data/COUNTRY/GHA/TRAINING_DATA/RGB/labels/000000000.tif')\n",
    "x = torch.tensor(snapshot_RGB)\n",
    "y = torch.tensor(snapshot_PAN)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visulaize your input chips\n",
    "f, axarr = plt.subplots(figsize=(10, 10))\n",
    "#torch.type(snapshot_RGB)\n",
    "plt.imshow(snapshot_RGB, cmap='gray')\n",
    "f, axarr = plt.subplots(figsize=(10, 10))\n",
    "plt.imshow(snapshot_PAN, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) If you need to convert Signed 16 bit to unsigned 8 bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "inFiles = []\n",
    "\n",
    "for root, dirs,  files in os.walk(data_path_chips):\n",
    "    for f in files:\n",
    "        if f[-4:] == '.tif':\n",
    "            inFiles.append(os.path.join(root, f))\n",
    "\n",
    "outFolder = data_path_chips + '/8uint8'\n",
    "\n",
    "if not os.path.exists(outFolder):\n",
    "    os.mkdir(outFolder)\n",
    "\n",
    "\n",
    "for f in inFiles:\n",
    "    curF = rasterio.open(f)\n",
    "    curD = curF.read()[0,:,:].astype('uint8')\n",
    "    curD = (curD > 0) * 1\n",
    "    curD = curD.astype('uint8')\n",
    "    profile = curF.profile\n",
    "    profile.update(count=1, dtype='uint8')\n",
    "    outFile = os.path.join(outFolder, os.path.basename(f))\n",
    "    with rasterio.open(outFile, 'w', **profile) as dst:\n",
    "        dst.write_band(1, curD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) If you need to covert .Shp to GEOJSON then to Binary Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inBuildings = os.path.join(data_path_p, 'Buildings.shp')\n",
    "gdf2 = gpd.read_file(inBuildings)\n",
    "badIdx = []\n",
    "for idx, row in gdf2.iterrows():\n",
    "   try:\n",
    "       xx = row['geometry'].area\n",
    "   except:\n",
    "       badIdx.append(idx)\n",
    "gdf2 = gdf2.drop(badIdx)\n",
    "fp_mask = sol.vector.mask.footprint_mask(gdf2, reference_im=os.path.join(data_path_j, 'raster_tiles/031111332333.tif'))\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "plt.imshow(fp_mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) If you need another way to do the same thing (e.g. GEOJSON to .tiff mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##make sure that you do not have any blank rows in your CSV referenced in the .yml\n",
    "geojson_dir = os.path.join(data_path, 'geojson')\n",
    "geojson_list = [f for f in os.listdir(geojson_dir) if f.endswith('.geojson')]\n",
    "im_list = [f for f in os.listdir(geojson_dir) if f.endswith('.tif')]\n",
    "n_chips = len(geojson_list)\n",
    "\n",
    "if not os.path.exists(masks):\n",
    "    os.mkdir(mask_dir)\n",
    "    \n",
    "    for idx, gj in enumerate(geojson_list):\n",
    "        # get the 'img[number] chip ID for the image'\n",
    "        chip_id = os.path.splitext(gj)[0].split('_')[-1]\n",
    "        matching_im = chip_id + '.tif'\n",
    "        mask_fname = 'masks' + chip_id + '.tif'\n",
    "        fp_mask = sol.vector.mask.footprint_mask(df=os.path.join(geojson_dir, gj),\n",
    "                                                 out_file=os.path.join(masks, mask_fname),\n",
    "                                                 reference_im=os.path.join(im_dir, matching_im),\n",
    "                                                 shape=(650, 650))\n",
    "        if (idx+1)%100 == 0:\n",
    "            print('chip {} of {} done'.format(idx+1, n_chips), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! We're ready to set up for training.\n",
    "\n",
    "### Building the config file\n",
    "\n",
    "With model fine-tuning, we'll load the pre-trained weights used above, and continue training at a much lower learning rate for a couple of epochs. To this end we'll need _another_ config with a few more modifications:\n",
    "\n",
    "1. A reduced learning rate - we'll try `1e-5` instead of `1e-4`\n",
    "2. Change `train=False` to `train=True`\n",
    "3. Specify where the newly trained versions are saved with the `training['callbacks']['model_checkpoint']` arguments\n",
    "4. Specify a training data CSV. In this case, we'll use a CSV created [per this tutorial](https://solaris.readthedocs.io/en/latest/tutorials/notebooks/creating_im_reference_csvs.html) that points to all of the images and the masks that we just created, save for one: the image that we inferenced against earlier, which we'll save as a test image. The csv, named `khartoum_fine_tune.csv`, is available in the `workshop_configs` directory.\n",
    "\n",
    "As earlier, feel free to create this config yourself; otherwise, you can use `xdxd_workshop_khartoum_train.yml`.\n",
    "\n",
    "### Model training\n",
    "\n",
    "Let's try it! <font style=\"color: red;\">__WARNING: this is EXTREMELY slow without a GPU (each epoch may take several hours).__</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model - Your .yml contains all the relevant parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config...\n",
      "config loaded. Initializing Trainer instance...\n",
      "model initialized. Beginning training...\n",
      "\n",
      "Beginning training epoch 0\n",
      "    loss at batch 0: 13.58376693725586\n",
      "    loss at batch 10: 13.813175201416016\n",
      "    loss at batch 20: 13.303665161132812\n",
      "    loss at batch 30: 13.779580116271973\n",
      "    loss at batch 40: 13.586511611938477\n",
      "    loss at batch 50: 13.071934700012207\n",
      "    loss at batch 60: 13.755105018615723\n",
      "    loss at batch 70: 13.624524116516113\n",
      "    loss at batch 80: 13.920515060424805\n",
      "    loss at batch 90: 13.080217361450195\n"
     ]
    }
   ],
   "source": [
    "print('Loading config...')\n",
    "config = sol.utils.config.parse('/home/wb447340/Notebooks/Imagery/Feature_Extraction/GHA_RGB_train.yml')\n",
    "print('config loaded. Initializing Trainer instance...')\n",
    "xdxd_trainer = sol.nets.train.Trainer(config)\n",
    "print('model initialized. Beginning training...')\n",
    "print()\n",
    "start_time = time.time()\n",
    "xdxd_trainer.train()\n",
    "end_time = time.time()\n",
    "print()\n",
    "print('training took {} minutes'.format((end_time-start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you got a CUDA out of memory error in the cell above, kill the kernels for the other jupyter notebooks (instructions at the top of this notebook for how to do so), re-load this notebook, and try again. Note that you'll need to re-run the first cell of this notebook (all of the imports) before you'll be able to run this one again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions with the new model\n",
    "\n",
    "We'll now run inference with the newly tuned model. Note that if your config file specifies `train=True` and you pass that config to an `Inferer` instance, `solaris` will automatically use the newly trained model for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "#torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading config...')\n",
    "config = sol.utils.config.parse(os.path.join(data_path_p, 'GHA_RGB_inf.yml'))\n",
    "print('config loaded. Initializing model...')\n",
    "xdxd_inferer = sol.nets.infer.Inferer(config)\n",
    "print('model initialized. Loading dataset...')\n",
    "inf_df = sol.nets.infer.get_infer_df(config)\n",
    "print('dataset loaded. Running inference on the image.')\n",
    "start_time = time.time()\n",
    "xdxd_inferer(inf_df)\n",
    "end_time = time.time()\n",
    "print('running inference on one image took {} seconds'.format(end_time-start_time))\n",
    "print('now go transform the output to vector...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outFolder = 'PREDICTIONS_VECTOR'\n",
    "if not os.path.exists(outFolder):\n",
    "   os.makedirs(outFolder)\n",
    "   \n",
    "for curImg in inf_df['image']:\n",
    "   predictionImage = os.path.join(data_path_p, 'PREDICTIONS_RGB', os.path.basename(curImg))\n",
    "   resulting_preds = skimage.io.imread(predictionImage)\n",
    "   resulting_preds = resulting_preds > 0\n",
    "   predicted_footprints = sol.vector.mask.mask_to_poly_geojson(\n",
    "       pred_arr=resulting_preds,\n",
    "       reference_im=curImg,\n",
    "       do_transform=True,\n",
    "       min_area=1e-10\n",
    "   )\n",
    "   try:\n",
    "       outFile = os.path.join(outFolder, os.path.basename(curImg).replace(\".tif\", \".json\"))\n",
    "       predicted_footprints.to_file(outFile, driver='GeoJSON')\n",
    "   except:\n",
    "       print('No footprints for %s' % predictionImage)\n",
    "fp_mask = sol.vector.mask.footprint_mask('chip_1_10.json')\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "plt.imshow(fp_mask, cmap='gnuplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axarr[0, 0].imshow(im_arr)\n",
    "axarr[0, 0].set_title('Source image', size=14)\n",
    "axarr[0, 0].axis('off')\n",
    "axarr[0, 1].imshow(old_preds, cmap='gray')\n",
    "axarr[0, 1].set_title('Predictions before fine-tuning', size=14)\n",
    "axarr[0, 1].axis('off')\n",
    "axarr[1, 1].imshow(new_preds, cmap='gray')\n",
    "axarr[1, 1].set_title('Predictions after fine-tuning', size=14)\n",
    "axarr[1, 1].axis('off')\n",
    "axarr[1, 0].imshow(ground_truth, cmap='gray')\n",
    "axarr[1, 0].set_title('Ground Truth', size=14)\n",
    "axarr[1, 0].axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. This appears to show a _marked_ improvement with _just three epochs of training!_ How do the scores come out?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring model performance after fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = sol.eval.base.Evaluator(os.path.join(data_path_p, 'Pred_RGB.geojson'))\n",
    "prediction_dirs = ['inference_out', 'retrain_inference_out']\n",
    "model_names = ['Original', 'Fine-tuned']\n",
    "\n",
    "f1_scores = []\n",
    "precision = []\n",
    "recall = []\n",
    "for i in range(2):\n",
    "    evaluator.load_proposal(os.path.join(prediction_dirs[i],'Pred_RGB.geojson'),\n",
    "                            pred_row_geo_value='geometry',\n",
    "                            conf_field_list=[])\n",
    "    results = evaluator.eval_iou(miniou=0.5, calculate_class_scores=False)\n",
    "    f1_scores.append(results[0]['F1Score'])\n",
    "    precision.append(results[0]['Precision'])\n",
    "    recall.append(results[0]['Recall'])\n",
    "\n",
    "f, axarr = plt.subplots(1, 3, figsize=(10, 4))\n",
    "f.subplots_adjust(wspace=0.6)\n",
    "axarr[0].bar(model_names, f1_scores)\n",
    "axarr[0].set_ylabel('$F_1$ Score', size=16)\n",
    "axarr[1].bar(model_names, precision)\n",
    "axarr[1].set_ylabel('Precision', size=16)\n",
    "axarr[2].bar(model_names, recall)\n",
    "axarr[2].set_ylabel('Recall', size=16);\n",
    "f.suptitle('Comparison of original vs. fine-tuned model performance', size=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, this is only _one_ sample image; however, it's noteworthy that this model briefly fine-tuned on Khartoum imagery [__achieved a higher score here than some of the prize-winning models trained on Khartoum for days during the SpaceNet Challenge Round 2__](https://medium.com/the-downlinq/2nd-spacenet-competition-winners-code-release-c7473eea7c11).\n",
    "\n",
    "# Congratulations! You've completed the FOSS4G 2019 Solaris tutorial.\n",
    "\n",
    "Hang around for a quick teaser on the SpaceNet 5 challenge that's starting soon! You're also welcome to explore the documentation or install solaris on your own machine and play around! We'll be here till the workshop ends and able to help.\n",
    "\n",
    "## What's next?\n",
    "\n",
    "Here are a few more resources that will help you as you continue to work with `solaris`:\n",
    "\n",
    "- [Solaris documentation](https://solaris.readthedocs.io)\n",
    "- [A blog post from Jake Shermeyer about using Solaris for car detection in the COWC dataset](https://medium.com/the-downlinq/beyond-infrastructure-mapping-finding-vehicles-with-solaris-11e08da0dab)\n",
    "- [The Solaris GitHub repository](https://github.com/cosmiq/solaris)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solaris",
   "language": "python",
   "name": "solaris"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
