{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code will iterate over multiple json files and will:\n",
    "<ol>\n",
    "\n",
    "  <li>Search</li>\n",
    "  <li>Apply Orders v2 Raster Functions</li>\n",
    "  <li>Order & Download</li>\n",
    "  <li>Receive Order Notification (Optional)</li>\n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orders v2 Notebook Pre-requisites:\n",
    "\n",
    "[Planet Account](https://www.planet.com/login/?mode=signup)\n",
    "\n",
    "[Planet API Key](https://www.planet.com/account/#/)\n",
    "\n",
    "[Anaconda with Python 3.7](https://www.anaconda.com/download/)\n",
    "\n",
    "   From the [Anaconda Navigator](https://docs.anaconda.com/anaconda/navigator/), open a terminal to install the geojson module: `pip install geojson` \n",
    "   \n",
    "   From the [Anaconda Navigator](https://docs.anaconda.com/anaconda/navigator/), open a terminal to install the Shapely module: `conda install -c scitools shapely`\n",
    "    \n",
    "   Note: *In Windows, run Terminal as Administrator if receiving a write permission error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import Session, get, post\n",
    "from time import sleep\n",
    "import glob\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import geopandas as pd\n",
    "import shapely.geometry\n",
    "import shapely.ops\n",
    "from shapely.geometry import mapping, shape\n",
    "\n",
    "\n",
    "# print function to format JSON\n",
    "def p(data):\n",
    "    print(json.dumps(data, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important References\n",
    "[Data API documentation](https://developers.planet.com/docs/api/)\n",
    "* [Items and Assets](https://developers.planet.com/docs/api/items-assets/)\n",
    "\n",
    "[Orders v2 documentation](https://developers.planet.com/docs/orders/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note about JSON files:\n",
    "\n",
    "* Windows directory format for **json_path** below: `\"C:\\\\subdirectory\\\\json_directory\\\\\"`\n",
    "* Mac Directory format for **json_path** below: `\"/Users/username/json_directory/\"`\n",
    "* GeoJSON(s) can be easily generate at [GeoJSON IO](http://geojson.io)\n",
    "* GeoJSON(s) must be in `.json` extension\n",
    "* This Orders v2 script **only** works with GeoJSON files with a **single Polygon feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Location of json files:\n",
    "json_path = '/data/ETH/' #Include trailing / in the json path\n",
    "                                       #Rename to .json\n",
    "\n",
    "#Percent coverage\n",
    "coverage_thresh = 0.90\n",
    "\n",
    "#Item Type: \"PSScene4Band\",\"SkySatScene\",\"PSScene3Band\",\"REScene\",\"REOrthoTile\",\"Sentinel2L1C\",\"SkySatCollect\",\"CustomL3A\",\"PSOrthoTile\",\"Landsat8L1G\"\n",
    "item_type = 'PSScene4Band'\n",
    "\n",
    "#Order Payload Params (e.g. visual, analytic, analytic_dn, analytic_sr, etc.):\n",
    "prod_bundle = \"analytic_sr\"\n",
    "\n",
    "#Temporal Search Params\n",
    "start_time = \"2019-05-01T00:00:00.000Z\"\n",
    "stop_time = \"2019-05-30T00:00:00.000Z\"\n",
    "\n",
    "#Other Filter Params\n",
    "min_gsd = 0.0\n",
    "max_cloud_cover = 0.2 #Cloud cover from 0 to 1\n",
    "\n",
    "API_TOKEN = os.environ.get(\"API_TOKEN\")\n",
    "USER = os.environ.get(\"USER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Notification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose between email notification OR webhook POST response below\n",
    "\n",
    "# Email notification\n",
    "email = True\n",
    "\n",
    "# Webhook Notification (Paid Customers Only)\n",
    "# Specify a webhook URL to be notified when the order is ready. Get a unique URL from https://webhook.site\n",
    "webhook = False\n",
    "webhook_url = \"<your webhook url>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Geometry (included in free trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'basepath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f79ca06ef32f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert Shape to Pandas Dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeojson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Ethiopia.shp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgeojson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geometry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'basepath' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert Shape to Pandas Dataframe\n",
    "import geojson\n",
    "inD = pd.read_file(os.path.join(basepath, \"Ethiopia.shp\"))\n",
    "geojson.Feature(inD.iloc[0]['geometry'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geojson\n",
    "geojson.Feature(inD.iloc[0]['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip a raster to an Area of Interest \n",
    "# The AOI can be specified by a polygon with up to 500 vertices\n",
    "clip = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Raster Functions (Paid Customers Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composite a set of raster files into one output.\n",
    "composite = True\n",
    "\n",
    "# Apply arbitrary band math to produce derived raster products.\n",
    "bandmath = False\n",
    "band_calc = \"(b4-b3)/(b4+b3)\" #NDVI\n",
    "pixel_type = \"32R\"\n",
    "\n",
    "# Deliver TOA product (applicable for analytic product only, NOT necessary for the analytic_sr product)\n",
    "toar = False\n",
    "toar_scale_factor = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate Session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORDERS_URL = \"https://api.planet.com/compute/ops/orders/v2/\"\n",
    "PLANET_API_KEY = os.getenv('PL_API_KEY') # Define PL_API_KEY as an evironment variable or type it below\n",
    "#PLANET_API_KEY = \"YOUR API KEY\"\n",
    "\n",
    "planet = Session()\n",
    "planet.auth = (PLANET_API_KEY, \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STOP - NO NEED TO EDIT THE CODE BELOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify the polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_poly(jsondata):\n",
    "\n",
    "    #Extract geometry from json file\n",
    "    json_geom = json_data['features'][0]['geometry']\n",
    "    num_coords = len(json_geom['coordinates'][0])\n",
    "\n",
    "    print (\"\")\n",
    "    print (\"The original polygon has {} points\".format(num_coords))\n",
    "    print (\"\")\n",
    "    \n",
    "    #Conver to shape and simplify polygon\n",
    "    shape_geom = shape(json_geom)\n",
    "    simple_poly = shape_geom.simplify(0.00001, preserve_topology=True)\n",
    "\n",
    "    #print simple_poly\n",
    "    simple_geom = mapping(simple_poly)\n",
    "    num_simple_coords = len(simple_geom['coordinates'][0])\n",
    "\n",
    "    print (\"\")\n",
    "    print (\"The simplified polygon has {} points\".format(num_simple_coords))\n",
    "    print (\"\")\n",
    "\n",
    "    json_data['features'][0]['geometry'] = simple_geom\n",
    "    \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exctract geometry from json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_geometries(data):\n",
    "\n",
    "    for feature in data['features']:\n",
    "        newcoords =  feature['geometry']['coordinates']\n",
    "\n",
    "    #Simplifying Polygon    \n",
    "\n",
    "    aoi_geometry = {\n",
    "      \"geometry\": {\n",
    "          \"type\": \"Polygon\",\n",
    "          \"coordinates\": newcoords \n",
    "      }\n",
    "    }\n",
    "\n",
    "    clip_geometry = {\n",
    "          \"type\": \"Polygon\",\n",
    "          \"coordinates\": newcoords \n",
    "      }\n",
    "    \n",
    "    p(aoi_geometry)\n",
    "    \n",
    "    return (aoi_geometry, clip_geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build query and search functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_search_all_pages(session, query):\n",
    "    r = session.post('https://api.planet.com/data/v1/quick-search', \n",
    "                     json=query)\n",
    "    if r.status_code != 200:\n",
    "        raise Exception(r.text)\n",
    "        raise Exception(\"HTTP %s\\n\\n%s\\n\\n%s\" % (\n",
    "            r.status_code, json.dumps(query, indent=2, sort_keys=True), r.text))\n",
    "\n",
    "    data = r.json()\n",
    "    items = data['features']\n",
    "\n",
    "    while data['_links'].get('_next'):\n",
    "        data = session.get(data['_links']['_next']).json()\n",
    "        items += data['features']\n",
    "    \n",
    "    return items\n",
    "\n",
    "\n",
    "def build_query(geometry, item_types=None, acquired_gte=None, acquired_lte=None,\n",
    "                gsd_gte=None, cloud_cover_lte=None):\n",
    "    \"\"\" example item_types: ['PSScene3Band']\n",
    "                acquired_gte: \"2016-01-01T00:00:00.000Z\"\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if 'features' in geometry:\n",
    "        geometry = geometry['features'][0]\n",
    "    \n",
    "    filters = [{\"type\": \"GeometryFilter\",\n",
    "                 \"field_name\": \"geometry\",\n",
    "                 \"config\": geometry['geometry']}]\n",
    "    \n",
    "    if acquired_gte:\n",
    "        filters.append({\n",
    "            \"type\": \"DateRangeFilter\",\n",
    "            \"field_name\": \"acquired\",\n",
    "            \"config\": {\"gte\": acquired_gte}})\n",
    "\n",
    "    if acquired_lte:\n",
    "        filters.append({\n",
    "            \"type\": \"DateRangeFilter\",\n",
    "            \"field_name\": \"acquired\",\n",
    "            \"config\": {\"lte\": acquired_lte}})\n",
    "\n",
    "    if gsd_gte is not None:\n",
    "        filters.append({\n",
    "            \"type\": \"RangeFilter\",\n",
    "            \"field_name\": \"gsd\",\n",
    "            \"config\": {\"gte\": float(gsd_gte)}})\n",
    "    \n",
    "    if cloud_cover_lte is not None:\n",
    "        filters.append({\n",
    "            \"type\": \"RangeFilter\",\n",
    "            \"field_name\": \"cloud_cover\",\n",
    "            \"config\": {\"lte\": float(cloud_cover_lte)}})        \n",
    "    \n",
    "    return {\n",
    "        \"interval\": \"day\",\n",
    "        \"item_types\": item_types,\n",
    "        \"filter\": {\n",
    "            \"type\": \"AndFilter\",\n",
    "            \"config\": filters}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify strip coverage meets coverage threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_strip(items, geometry):\n",
    "    strips = []\n",
    "    aoi = shapely.geometry.Polygon(geometry['geometry']['coordinates'][0])\n",
    "\n",
    "    for strip_id, items_iter in itertools.groupby(items, lambda item: item['properties']['strip_id']):\n",
    "        strip_items = list(items_iter)\n",
    "        strip_polys = []\n",
    "        for item in strip_items:\n",
    "            geo_type = item['geometry']['type']\n",
    "            if geo_type == 'Polygon':\n",
    "                coords = item['geometry']['coordinates'][0]\n",
    "                strip_polys.append(shapely.geometry.Polygon(coords))\n",
    "            elif geo_type == 'MultiPolygon':\n",
    "                for coords in item['geometry']['coordinates'][0]:\n",
    "                    strip_polys.append(shapely.geometry.Polygon(coords))\n",
    "            else:\n",
    "                raise Exception('type %s is unsupported !!! fixme' % geo_type)\n",
    "\n",
    "        strip_poly = shapely.ops.cascaded_union(strip_polys)\n",
    "        coverage_percent = aoi.intersection(strip_poly).area / aoi.area\n",
    "        strips.append({\n",
    "            'strip_id': strip_id,\n",
    "            'items': strip_items,\n",
    "            'coverage': coverage_percent,\n",
    "            'datetime': strip_items[0]['properties']['acquired']\n",
    "        })\n",
    "       \n",
    "    return sorted(strips, key=lambda strip: strip['datetime'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the image strips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items_with_coverage(session, geometry, item_types, **filters):\n",
    "    query_json = build_query(geometry, item_types, **filters)\n",
    "    all_items = quick_search_all_pages(session, query_json)\n",
    "    return group_by_strip(all_items, geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Individual Images Intersect with the AOI (TM Variation in comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will verify that individual images intersect with the clip AOI to prevent order failure\n",
    "def img_intersection(thresholded_strips, geometry):\n",
    "\n",
    "    aoi = shapely.geometry.Polygon(geometry['geometry']['coordinates'][0])\n",
    "    verified_all = []\n",
    "    verified_items = []\n",
    "    removed_items = []\n",
    "    \n",
    "    for i in range(0,len(thresholded_strips)):\n",
    "    \n",
    "        for item in thresholded_strips[i][\"items\"]:\n",
    "            geo_type2 = item['geometry']['type']\n",
    "\n",
    "            img_coords = shapely.geometry.Polygon(item['geometry']['coordinates'][0])\n",
    "            coverage_percent = aoi.intersection(img_coords).area / aoi.area\n",
    "            \n",
    "            if coverage_percent > 0:\n",
    "                \n",
    "                strip_items = item['id']\n",
    "                strip_id = item['properties']['strip_id']\n",
    "                verified_items.append(item['id'])\n",
    "                verified_all.append({\n",
    "                    'strip_id': strip_id,\n",
    "                    'items': strip_items,\n",
    "                })\n",
    "            \n",
    "            else:\n",
    "                removed_items.append(item['id'])\n",
    "                continue\n",
    "\n",
    "    return (verified_items, removed_items, verified_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by Strips (Composite Order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_imgs_by_stripid(verified_all,verified):\n",
    "    grouped_by_strip = []\n",
    "    # group items by unique strip_id\n",
    "    for key, group in itertools.groupby(verified_all, key=lambda x:x['strip_id']):\n",
    "        strip_id = key\n",
    "        strip_items = []\n",
    "        group_values = list(group)\n",
    "        for key, group in itertools.groupby(group_values, key=lambda x:x['items']):\n",
    "            strip_items.append(key)\n",
    "\n",
    "        grouped_by_strip.append({ \n",
    "            'strip_id': strip_id,\n",
    "            'strip_items': strip_items\n",
    "        })\n",
    "    return grouped_by_strip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamically generate order_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_order_payload(dir_name,items_by_strips,item_type,prod_bundle,clip,clip_geometry,toar,toar_scale_factor,\n",
    "                                  bandmath,band_calc,pixel_type,composite,email,webhook,webhook_url):\n",
    "    \n",
    "\n",
    "    composite_orders = []\n",
    "    for i in range(0,len(items_by_strips)):\n",
    "        \n",
    "        #Grab each strip_id for formatting order_name\n",
    "        strip_id = items_by_strips[i]['strip_id']\n",
    "        \n",
    "        #Grab all item_ids for each strip\n",
    "        item_ids = items_by_strips[i]['strip_items']        \n",
    "        \n",
    "        #Extract Date from Image ID\n",
    "        imgID = json.dumps(item_ids[0])\n",
    "        date_str = imgID[1:9]\n",
    "\n",
    "        order_name = date_str + \"_\" + strip_id + \"_\" + prod_bundle\n",
    "        print (order_name)\n",
    "        \n",
    "        # Create a new tool dictionary\n",
    "        tools = []\n",
    "        \n",
    "        # Add each tool component\n",
    "        if clip:\n",
    "            tools.append({'clip': {\"aoi\": clip_geometry}})\n",
    "    \n",
    "        if toar:\n",
    "            tools.append({'toar': {\"scale_factor\": toar_scale_factor}})\n",
    "    \n",
    "        if bandmath:\n",
    "            tools.append({'bandmath': {\n",
    "                \"b1\" : band_calc,\n",
    "                \"pixel_type\": pixel_type\n",
    "            }})\n",
    "\n",
    "        if composite:\n",
    "            tools.append({'composite': {}})\n",
    "            \n",
    "        \n",
    "\n",
    "        #Add pfa tools to order_payload\n",
    "        order_payload={\n",
    "            \"name\": order_name,\n",
    "            \"products\": [\n",
    "                    {\n",
    "                    \"item_ids\": item_ids,\n",
    "                    \"item_type\": item_type,\n",
    "                    \"product_bundle\": prod_bundle\n",
    "                    }\n",
    "                ]\n",
    "        }\n",
    "        \n",
    "        #Payload generation w/ tools and alternate delivery methods\n",
    "        if email:\n",
    "            order_payload['notifications']={\"email\": email}\n",
    "        if webhook:\n",
    "            order_payload['notifications']={\"webhook\":{\"per_order\": webhook,\"url\": webhook_url}}\n",
    "            \n",
    "        if any ((clip, toar, composite)):\n",
    "            order_payload['tools'] = tools\n",
    "       \n",
    "        p(order_payload)\n",
    "    \n",
    "        composite_orders.append(order_payload)\n",
    "    \n",
    "    return composite_orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Composite Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_composite_orders(composite_orders):\n",
    "    \n",
    "    order_urls = []\n",
    "    failed_orders = []\n",
    "    success_count = 0\n",
    "    for count, order in enumerate(composite_orders):\n",
    "        \n",
    "        response = planet.post(ORDERS_URL, json=order)\n",
    "        \n",
    "        if response.status_code == 202:\n",
    "            order_id = response.json()[\"id\"]\n",
    "            success_count += 1 \n",
    "            print (\"Order submitted with ID {}\".format(order_id))\n",
    "        else:\n",
    "            failed_orders.append(order)\n",
    "            msg = response.json().get(\"message\")\n",
    "            print ('Order failed with code {} and message \"{}\"'.format(response.status_code, msg))\n",
    "            \n",
    "\n",
    "        order_url = ORDERS_URL + order_id\n",
    "        print (\"Submitted {}\".format(order_url))\n",
    "        order_urls.append(order_url)\n",
    "\n",
    "        \n",
    "        sleep(1)\n",
    "    print (\"\")\n",
    "    print (\"{} out of {} orders have been successfully submitted\".format(success_count, count+1))\n",
    "    print (\"\")\n",
    "    \n",
    "    return order_urls, failed_orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Order Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_response(order_urls):\n",
    "    \n",
    "    for order_url in order_urls:\n",
    "\n",
    "        #Retrieve order state\n",
    "        response = planet.get(order_url)\n",
    "        \n",
    "        order = response.json()\n",
    "        print (\"order state is:\", order['state'])\n",
    "        \n",
    "        print (\"\")\n",
    "        p(order)\n",
    "        print (\"\")\n",
    "        \n",
    "        while order['state'] == 'running':\n",
    "            sleep(5)\n",
    "            # Overwrite existing order with a new response\n",
    "            order = planet.get(order_url).json()\n",
    "            print (\"order state is:\", order['state'])\n",
    "        \n",
    "        if order[\"state\"] == \"success\":\n",
    "            results_link = order[\"_links\"][\"results\"]\n",
    "            order_name = order[\"name\"]\n",
    "            yield results_link, order_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ##########################   Download    ########################## # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download multiple orders (Composite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_results(order_urls, img_dir):\n",
    "    \n",
    "    files = []\n",
    "    for asset, order_name in check_response(order_urls):\n",
    "     \n",
    "        for order_asset in asset:\n",
    "\n",
    "            name = order_asset[\"name\"]\n",
    "            print (name)\n",
    "            fn = os.path.basename(name)\n",
    "            location = order_asset[\"location\"]\n",
    "            \n",
    "            res = planet.get(location, stream=True)\n",
    "            sleep(1) # Time in seconds. Added this delay and failures to download stopped.\n",
    "\n",
    "            full_fn = img_dir + order_name + \"_\" + fn\n",
    "            if os.path.exists(full_fn):\n",
    "                print (\"{} already exists, skipping\".format(full_fn))\n",
    "                continue\n",
    "                   \n",
    "            print (\"The filename is: {}\".format(full_fn))\n",
    "\n",
    "            with open(full_fn, \"wb\") as f:\n",
    "                for chunk in res.iter_content(chunk_size=1024):\n",
    "                    if chunk: # filter out keep-alive new chunks\n",
    "                        f.write(chunk)\n",
    "                        f.flush()\n",
    "                    \n",
    "            files.append(full_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main \n",
    "\n",
    "# Get geometry from json files, build queries, extract ids, and download\n",
    "for json_file in sorted(glob.glob(json_path+\"/*.json\")):\n",
    "    print (json_file)\n",
    "    \n",
    "    #Generate Image Directory for results\n",
    "    dir_name = os.path.splitext(os.path.basename(json_path + json_file))[0]\n",
    "    img_path = json_path + dir_name + '/'\n",
    "    print (img_path)\n",
    "    \n",
    "    #Create directory if it doesn't already exist\n",
    "    if not os.path.exists(img_path):\n",
    "        os.makedirs(img_path)\n",
    "    \n",
    "    #Load json file\n",
    "    with open(json_file) as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    #Simplify Polygon\n",
    "    simple_json = simplify_poly(json_data)\n",
    "    \n",
    "    #Extract geometry from json file\n",
    "    (aoi_geometry, clip_geometry) = extract_geometries(simple_json)\n",
    "    \n",
    "    #Get Stip Coverage Information\n",
    "    strips = get_items_with_coverage(planet,\n",
    "                                 aoi_geometry,\n",
    "                                 [item_type],\n",
    "                                 acquired_gte=start_time,\n",
    "                                 acquired_lte=stop_time,\n",
    "                                 gsd_gte=min_gsd,\n",
    "                                 cloud_cover_lte=max_cloud_cover)\n",
    "\n",
    "    print (\"there are a total of %s strips\" % len(strips))\n",
    "    print (\" \")\n",
    "    \n",
    "    #Check coverage for the strips\n",
    "    \n",
    "    thresholded_strips = [s for s in strips if s['coverage'] >= coverage_thresh]\n",
    "\n",
    "    print (\"there are %s strips with at least %0.2f coverage\" % (len(thresholded_strips), coverage_thresh))\n",
    "    print (\" \")\n",
    "    \n",
    "    #Check images intersect with clip AOI\n",
    "    (verified_items, removed_items, verified_all) = img_intersection(thresholded_strips,aoi_geometry)\n",
    "    \n",
    "    #Group all of the images by their strip IDs\n",
    "    imgids_by_strips = group_imgs_by_stripid(verified_all,verified_items)\n",
    "    \n",
    "    #Create order payloads\n",
    "    #order_payload = generate_order_payload(dir_name,item_ids,clip_geometry)\n",
    "    order_payloads = generate_order_payload(dir_name,imgids_by_strips,item_type,prod_bundle,clip,clip_geometry,\n",
    "                                      toar,toar_scale_factor,bandmath,band_calc,pixel_type,\n",
    "                                      composite,email,webhook,webhook_url)\n",
    "\n",
    "    #Save Order_Payload Sample\n",
    "    order_fn = img_path + 'Order_Payload.json'\n",
    "    order_payload = order_payloads[0]\n",
    "    \n",
    "    with open(order_fn, 'w') as f:\n",
    "        json.dump(order_payload, f, indent=2)\n",
    "        \n",
    "    #Submit composite orders\n",
    "    #response = planet.post(ORDERS_URL, json=order_payload)\n",
    "    (order_urls, failed_orders) = submit_composite_orders(order_payloads)    \n",
    " \n",
    "    download_results(order_urls, img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Planet",
   "language": "python",
   "name": "planet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
